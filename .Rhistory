mean(stayed$YearsWithCurrManager)#Average years with Manager of those who stay
#4.36 Years
gender_influence <- employee %>% group_by(Gender, JobRole) %>% summarise(average_monthly_income=mean(MonthlyIncome))
gender_influence_monthlyincome <- gender_influence %>% mutate(round_income=round(average_monthly_income))
ggplot(gender_influence_monthlyincome, aes(x=Gender,y=average_monthly_income, color=Gender))+
geom_bar(stat = "identity",width=0.5,position=position_dodge())+
geom_text(aes(label=round_income), vjust=1.6, color="white",
position = position_dodge(0.9), size=3.5)+
facet_wrap(~JobRole)+
theme_minimal()+
scale_fill_manual(values=c("red", "blue"))+
ggtitle("Monthly incomes across Job Roles")+
scale_y_continuous(name="Average Monthly Income")
female_loss <- str_count(quit$Gender, "Female") %>% sum()
male_loss <- str_count(quit$Gender, "Male") %>% sum()
male_total <- str_count(employee$Gender, "Male") %>% sum()
female_total <- str_count(employee$Gender, "Female") %>% sum()
loss_rate_male <- male_loss/nrow(employee)
loss_rate_female <- female_loss/nrow(employee)
loss_rate_female
loss_rate_male
female_total/nrow(employee)
depart_loss <- quit %>% group_by(Department,Gender)
quit %>% ggplot()+
geom_histogram(stat = count(quit$JobRole))
employee <- read_csv("WA_Fn-UseC_-HR-Employee-Attrition.csv")
quit <- filter(employee, Attrition=="Yes")
stayed <- filter(employee, Attrition=="No")
nrow(quit)
#237
nrow(stayed)
#1233
retention_rate <- nrow(quit)/nrow(employee)
#16.12%
mean(quit$YearsWithCurrManager) #Average years with Manager of those who quit
#2.85 Years
mean(stayed$YearsWithCurrManager)#Average years with Manager of those who stay
#4.36 Years
gender_influence <- employee %>% group_by(Gender, JobRole) %>% summarise(average_monthly_income=mean(MonthlyIncome))
gender_influence_monthlyincome <- gender_influence %>% mutate(round_income=round(average_monthly_income))
ggplot(gender_influence_monthlyincome, aes(x=Gender,y=average_monthly_income, color=Gender))+
geom_bar(stat = "identity",width=0.5,position=position_dodge())+
geom_text(aes(label=round_income), vjust=1.6, color="white",
position = position_dodge(0.9), size=3.5)+
facet_wrap(~JobRole)+
theme_minimal()+
scale_fill_manual(values=c("red", "blue"))+
ggtitle("Monthly incomes across Job Roles")+
scale_y_continuous(name="Average Monthly Income")
female_loss <- str_count(quit$Gender, "Female") %>% sum()
male_loss <- str_count(quit$Gender, "Male") %>% sum()
male_total <- str_count(employee$Gender, "Male") %>% sum()
female_total <- str_count(employee$Gender, "Female") %>% sum()
loss_rate_male <- male_loss/nrow(employee)
loss_rate_female <- female_loss/nrow(employee)
loss_rate_female
loss_rate_male
female_total/nrow(employee)
depart_loss <- quit %>% group_by(Department,Gender)
quit <- quit %>%
mutate(JobRole = factor(JobRole))
quit %>% ggplot()+
geom_histogram(stat = count(quit$JobRole))
shiny::runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
shiny::runApp('dashboard')
install.libraries("Hmisc")
install.packages("Hmisc")
install.packages("PerformanceAnalytics")
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('2_eda/initial_results')
shiny::runApp('dashboard')
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
install.packages(c("curl", "formatR", "Hmisc", "htmltools", "psych", "RcppEigen", "rmarkdown", "shiny", "SparseM", "tidyr"))
install.packages(c("foreign", "Matrix"), lib="/usr/local/Cellar/r/3.4.0_1/R.framework/Versions/3.4/Resources/library")
shiny::runApp('dashboard')
install.packages("mnormt")
runApp('dashboard')
install.packages("xts")
runApp('dashboard')
install.packages("PerformanceAnalytics")
install.packages("PerformanceAnalytics")
runApp('dashboard')
install.packages("hmisc")
install.packages("Hmisc")
runApp('dashboard')
install.packages("Hmisc")
install.packages("acepack")
install.packages("Hmisc")
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
chart.Correlation(numeric, histogram=TRUE, pch=19)
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
shiny::runApp('dashboard')
install.libraries(c("caret", "pROC", "DMwR"))
install.packages(c("caret", "pROC", "DMwR"))
install.packages("minqa")
install.packages("quantreg")
knitr::opts_chunk$set(echo = TRUE)
library(pROC)
library(tidyverse)
library(caret)
library(DMwR)
data <- read.csv('/Users/riapan/Desktop/final_project_390/HR-Employee-Attrition.csv')
knitr::opts_chunk$set(echo = TRUE)
library(pROC)
library(tidyverse)
library(caret)
library(DMwR)
data <- read.csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')
data<- data[-27]
data <- data[-22]
data <- data[-9]
dummy <- model.matrix(Attrition ~ ., data)
new <- data.frame(dummy)
new <- new[,-1]
Attrition <- data$Attrition
dataDummy <- cbind(Attrition,new)
dataDummy
#check to find that the data is skewed
ggplot(dataDummy) + geom_histogram(aes (x = Attrition),stat = "count")
prop.table(table(dataDummy$Attrition))
table(dataDummy$Attrition)
#split data into train and test
set.seed(1234)
splitIndex <- createDataPartition(dataDummy$Attrition, p =0.8, list =FALSE, times =1)
test <- dataDummy[-splitIndex,]
train <- dataDummy[splitIndex,]
#oversample train data to balance
trainBalance <- SMOTE(Attrition ~ ., train, perc.over = 400, perc.under=131)
table(trainBalance$Attrition)
prop.table(table(trainBalance$Attrition))
#NEED IMPLEMENT
set.seed(1234) #set seed to reproducible
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(Attrition~., data = trainBalance, method = "rf", trControl =ctrl)
knitr::opts_chunk$set(echo = TRUE)
library(pROC)
library(tidyverse)
library(caret)
library(DMwR)
library(randomForest)
library(e1071)
install.packages('e1071')
knitr::opts_chunk$set(echo = TRUE)
library(pROC)
library(tidyverse)
library(caret)
library(DMwR)
library(randomForest)
library(e1071)
data <- read.csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')
data<- data[-27]
data <- data[-22]
data <- data[-9]
dummy <- model.matrix(Attrition ~ ., data)
new <- data.frame(dummy)
new <- new[,-1]
Attrition <- data$Attrition
dataDummy <- cbind(Attrition,new)
dataDummy
#check to find that the data is skewed
ggplot(dataDummy) + geom_histogram(aes (x = Attrition),stat = "count")
prop.table(table(dataDummy$Attrition))
table(dataDummy$Attrition)
#split data into train and test
set.seed(1234)
splitIndex <- createDataPartition(dataDummy$Attrition, p =0.8, list =FALSE, times =1)
test <- dataDummy[-splitIndex,]
train <- dataDummy[splitIndex,]
#oversample train data to balance
trainBalance <- SMOTE(Attrition ~ ., train, perc.over = 400, perc.under=131)
table(trainBalance$Attrition)
prop.table(table(trainBalance$Attrition))
set.seed(1234) #set seed to reproducible
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(Attrition~., data = trainBalance, method = "rf", trControl =ctrl)
print(rf_model)
plot(rf_model)
importance <- varImp(rf_model, scale=FALSE)
importance
#rf_model$importance
predictors <- names(trainBalance)[names(trainBalance) != 'Attrition']
pred_rf <- predict(rf_model$finalModel, test[,predictors],type = "prob")
pred_rf
auc <- roc(test$Attrition, pred_rf[,1])
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
#since the best mtry = 3
importance_grid <- varImp(rf_gridsearch,scale = FALSE)
runApp('dashboard')
install.packages("corrplot")
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
knitr::opts_chunk$set(echo = TRUE)
library(pROC)
library(tidyverse)
library(caret)
library(DMwR)
library(randomForest)
library(e1071)
library(tidyverse)
data <- read.csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')
data<- data[-27]
data <- data[-22]
data <- data[-9]
dummy <- model.matrix(Attrition ~ ., data)
new <- data.frame(dummy) # change back to a datafram
new <- new[,-1] # get rid first useless columne
Attrition <- data$Attrition
dataDummy <- cbind(Attrition,new) #add Attrition back
head(dataDummy)
#check to find that the data is skewed
ggplot(dataDummy) + geom_histogram(aes (x = Attrition),stat = "count")
prop.table(table(dataDummy$Attrition))
table(dataDummy$Attrition)
#split data into train and test
library(caret)
set.seed(1234)
splitIndex <- createDataPartition(dataDummy$Attrition, p =0.8, list =FALSE, times =1)
test <- dataDummy[-splitIndex,]
train <- dataDummy[splitIndex,]
#oversample train data to balance
library(DMwR)
trainBalance <- SMOTE(Attrition ~ ., train, perc.over = 400, perc.under=131)
table(trainBalance$Attrition)
prop.table(table(trainBalance$Attrition))
#NEED IMPLEMENT
library(caret)
set.seed(1234) #set seed to reproducible
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(Attrition~., data = trainBalance, method = "rf", trControl =ctrl)
print(rf_model)
plot(rf_model)
predictors <- names(trainBalance)[names(trainBalance) != 'Attrition']
pred_rf <- predict(rf_model$finalModel, test[,predictors],type = "prob")
#use AUC to measure the prediction
auc <- roc(test$Attrition, pred_rf[,1])
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
#grid search
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")
set.seed(1234)
#since the ideal mtry is between sqrtq to 2/q.
tunegrid <- expand.grid(.mtry=c(1:23))
#tunegrid <- expand.grid(.mtry=8)
rf_gridsearch <- train(Attrition~., data=trainBalance, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
predictors <- names(trainBalance)[names(trainBalance) != 'Attrition']
pred_rf_gridsearch <- predict(rf_gridsearch$finalModel, test[,predictors],type = "prob") # predictive model, change 'predictors'
knitr::opts_chunk$set(echo = TRUE)
library(pROC)
library(tidyverse)
library(caret)
library(DMwR)
library(randomForest)
library(e1071)
library(tidyverse)
data <- read.csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')
data<- data[-27]
data <- data[-22]
data <- data[-9]
dummy <- model.matrix(Attrition ~ ., data)
new <- data.frame(dummy) # change back to a datafram
new <- new[,-1] # get rid first useless columne
Attrition <- data$Attrition
dataDummy <- cbind(Attrition,new) #add Attrition back
head(dataDummy)
#check to find that the data is skewed
ggplot(dataDummy) + geom_histogram(aes (x = Attrition),stat = "count")
prop.table(table(dataDummy$Attrition))
table(dataDummy$Attrition)
#split data into train and test
library(caret)
set.seed(1234)
splitIndex <- createDataPartition(dataDummy$Attrition, p =0.8, list =FALSE, times =1)
test <- dataDummy[-splitIndex,]
train <- dataDummy[splitIndex,]
#oversample train data to balance
library(DMwR)
trainBalance <- SMOTE(Attrition ~ ., train, perc.over = 400, perc.under=131)
table(trainBalance$Attrition)
prop.table(table(trainBalance$Attrition))
library(caret)
set.seed(1234) #set seed to reproducible
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(Attrition~., data = trainBalance, method = "rf", trControl =ctrl)
print(rf_model)
plot(rf_model)
library(pROC)
predictors <- names(trainBalance)[names(trainBalance) != 'Attrition']
pred_rf <- predict(rf_model$finalModel, test[,predictors],type = "prob")
#use AUC to measure the prediction
auc <- roc(test$Attrition, pred_rf[,1])
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(1234)
tunegrid <- expand.grid(.mtry= 3)
rf_optimal <- train(Attrition~., data=trainBalance, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
rf_optimal
predictors <- names(trainBalance)[names(trainBalance) != 'Attrition']
predictors
pred_rf_gridsearch <- predict(rf_optimal$finalModel,test[,predictors],type = "prob")
pred_rf_gridsearch
auc <- roc(test$Attrition, pred_rf_gridsearch[,1])
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
slData <- data[, c("OverTime", "StockOptionLevel","TotalWorkingYears",
"MonthlyIncome","JobInvolvement","Age","EnvironmentSatisfaction", "JobSatisfaction",
"YearsWithCurrManager","YearsAtCompany","JobLevel","YearsInCurrentRole",
"DailyRate","EmployeeNumber","TrainingTimesLastYear","DistanceFromHome","Education",
"NumCompaniesWorked","HourlyRate","WorkLifeBalance")]
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
knitr::opts_chunk$set(echo = TRUE)
library(pROC)
library(tidyverse)
library(caret)
library(DMwR)
library(randomForest)
library(e1071)
#can't do read_csv here, need be "dataframe"
data <- read.csv('IBM-HR-Employee-Attrition.csv')
View(data)
View(data)
unique(data$StockOptionLevel)
unique(data$TotalWorkingYears)
unique(data$JobInvolvement)
unique(data$Age)
unique(data$EnvironmentSatisfaction)
unique(data$JobSatisfaction)
unique(data$JobLevel)
unique(data$EmployeeNumber)
unique(data$TrainingTimesLastYear)
unique(data$Education)
unique(data$WorkLifeBalance)
unique(data$MaritalStatusMarried)
shiny::runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
?not
runApp('dashboard')
unique(data$MaritalStatusMarried)
unique(data$MaritalStatus)
colnames(test)
knitr::opts_chunk$set(echo = TRUE)
library(pROC)
library(tidyverse)
library(caret)
library(DMwR)
library(randomForest)
library(e1071)
#can't do read_csv here, need be "dataframe"
data <- read.csv('IBM-HR-Employee-Attrition.csv')
data<- data[-27]
data <- data[-22]
data <- data[-9]
dummy <- model.matrix(Attrition ~ ., data)
new <- data.frame(dummy) # change back to a datafram
new <- new[,-1] # get rid first useless columne
Attrition <- data$Attrition
dataDummy <- cbind(Attrition,new) #add Attrition back
head(dataDummy[,3:4])
#check to find that the data is skewed
ggplot(dataDummy) + geom_histogram(aes (x = Attrition),stat = "count")
prop.table(table(dataDummy$Attrition))
table(dataDummy$Attrition)
#split data into train and test
set.seed(1234)
splitIndex <- createDataPartition(dataDummy$Attrition, p =0.8, list =FALSE, times =1)
test <- dataDummy[-splitIndex,]
train <- dataDummy[splitIndex,]
#oversample train data to balance
trainBalance <- SMOTE(Attrition ~ ., train, perc.over = 400, perc.under=131)
table(trainBalance$Attrition)
prop.table(table(trainBalance$Attrition))
set.seed(1234) #set seed to reproducible
ctrl <- trainControl(method = "cv", number = 5)
rf_model <- train(Attrition~., data = trainBalance, method = "rf", trControl =ctrl)
print(rf_model)
plot(rf_model)
predictors <- names(trainBalance)[names(trainBalance) != 'Attrition']
pred_rf <- predict(rf_model$finalModel, test[,predictors],type = "prob")
#use AUC to measure the prediction
auc <- roc(test$Attrition, pred_rf[,1])
print(auc)
plot(auc, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(1234)
tunegrid <- expand.grid(.mtry= 3)
rf_optimal <- train(Attrition~., data=trainBalance, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
rf_optimal
predictors <- names(trainBalance)[names(trainBalance) != 'Attrition']
pred_rf_gridsearch <- predict(rf_optimal$finalModel,test[,predictors],type = "prob")
auc <- roc(test$Attrition, pred_rf_gridsearch[,1])
print(auc)
plot(auc, ylim=c(0,1),  print.thres=TRUE, main=paste('AUC:',round(auc$auc[[1]],2)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2)
#since the best mtry = 3
importance_grid <- varImp(rf_optimal,scale = FALSE)
print(importance_grid)
#plot(importance_grid)
ggplot(importance_grid)+ggtitle("Random Forest Feature Importance")
# Select the subset of data only containing important 21 features
dataSlct <- data[, c("Attrition", "OverTime", "StockOptionLevel","TotalWorkingYears",
"MonthlyIncome","JobInvolvement","Age","EnvironmentSatisfaction", "JobSatisfaction",
"YearsWithCurrManager","YearsAtCompany","JobLevel","YearsInCurrentRole",
"DailyRate","EmployeeNumber","TrainingTimesLastYear","DistanceFromHome","Education",
"NumCompaniesWorked","HourlyRate","WorkLifeBalance","MaritalStatus")]
#create dummy variable
dummySlct <- model.matrix(Attrition ~ ., dataSlct)
new <- data.frame(dummySlct) # change back to a datafram
new <- new[,-1] # get rid first useless columne
Attrition <- dataSlct$Attrition
dataDummy <- cbind(Attrition,new) #add Attrition back
#partition
set.seed(1234)
splitIndex <- createDataPartition(dataDummy$Attrition, p =0.8, list =FALSE, times =1)
test <- dataDummy[-splitIndex,]
train <- dataDummy[splitIndex,]
#oversampling
trainBalance <- SMOTE(Attrition ~ ., train, perc.over = 400, perc.under=131)
table(trainBalance$Attrition)
prop.table(table(trainBalance$Attrition))
#building modeling
control <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(1234)
tunegrid <- expand.grid(.mtry= 3)
rf_optimal <- train(Attrition~., data=trainBalance, method="rf", metric="Accuracy", tuneGrid=tunegrid, trControl=control)
rf_optimal
saveRDS(rf_optimal, file = "rf_optimal.rda")
colnames(test)
colnames(test)
head(test$MaritalStatusMarried)
head(test$MaritalStatusSingle)
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
colnames(test)
head(test$MaritalStatusMarried)
head(test$OvertimeYes)
colnames(test)
head(test$MaritalStatusMarried)
head(test$Overtime)
colnames(test)
head(test$MaritalStatusMarried)
head(test$OverTimeYes)
runApp('dashboard')
runApp('dashboard')
unique(test$JobInvolvement)
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
install.packages('ggthemes')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('dashboard')
runApp('2_analysis/results/dashboard')
